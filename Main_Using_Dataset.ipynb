{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-18T13:49:13.460448Z",
     "start_time": "2025-03-18T13:49:04.407935Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# ‚úÖ Step 1: Load & Process Dataset\n",
    "file_path = \"Extracted_Medical_Q_A.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ‚úÖ Debugging: Check Available Columns\n",
    "print(\"üìä Available Columns:\", df.columns)\n",
    "\n",
    "# ‚úÖ Ensure \"Question\" & \"Answer\" Columns Exist\n",
    "if \"Question\" not in df.columns or \"Clean_Answer\" not in df.columns:\n",
    "    raise KeyError(\"‚ùå Missing 'Question' or 'Clean_Answer' column in dataset.\")\n",
    "\n",
    "# ‚úÖ Step 2: Remove Duplicates & NaNs\n",
    "df = df.dropna(subset=[\"Question\", \"Clean_Answer\"]).drop_duplicates(subset=[\"Question\"]).reset_index(drop=True)\n",
    "\n",
    "# ‚úÖ Debugging: Print Extracted Questions\n",
    "print(\"\\nüì¢ Extracted Questions Sample:\")\n",
    "print(df[\"Question\"].head(10))\n",
    "\n",
    "# ‚úÖ Step 3: Load Pretrained BERT Model\n",
    "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Lightweight & optimized for Q&A\n",
    "\n",
    "# ‚úÖ Step 4: Compute BERT Sentence Embeddings for Questions\n",
    "question_embeddings = bert_model.encode(df[\"Question\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "# ‚úÖ Debugging: Check Shape of Embeddings\n",
    "print(\"\\nüìä Question Embeddings Shape:\", question_embeddings.shape)\n",
    "\n",
    "if question_embeddings.shape[0] == 0:\n",
    "    raise ValueError(\"‚ùå No question embeddings found. Check dataset processing!\")\n",
    "\n",
    "# ‚úÖ Step 5: Improved Token Processing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Tokenizes and preprocesses input text:\n",
    "    - Removes stopwords\n",
    "    - Applies lemmatization\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text.lower())  # Convert to lowercase & tokenize\n",
    "    processed_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return \" \".join(processed_tokens)\n",
    "\n",
    "# ‚úÖ Step 6: Train TF-IDF Model on Processed Questions\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"Question\"].apply(preprocess_text))\n",
    "\n",
    "# ‚úÖ Step 7: Hybrid Retrieval (BERT + TF-IDF)\n",
    "def retrieve_best_answer(input_question, top_k=3):\n",
    "    \"\"\"\n",
    "    Uses a hybrid approach (TF-IDF + BERT) to retrieve the best-matched question and return the corresponding answer.\n",
    "    \"\"\"\n",
    "    # üîπ Process input question\n",
    "    processed_input = preprocess_text(input_question)\n",
    "\n",
    "    # üîπ TF-IDF Similarity\n",
    "    input_vector = vectorizer.transform([processed_input])\n",
    "    tfidf_scores = np.dot(input_vector, tfidf_matrix.T).toarray().flatten()\n",
    "\n",
    "    # üîπ BERT Similarity\n",
    "    input_embedding = bert_model.encode([input_question], convert_to_tensor=True).view(1, -1)\n",
    "    bert_scores = util.pytorch_cos_sim(input_embedding, question_embeddings)[0].cpu().numpy()\n",
    "\n",
    "    # üîπ Combine Scores (Weighted Sum)\n",
    "    final_scores = (tfidf_scores * 0.4) + (bert_scores * 0.6)  # Adjust weights for better accuracy\n",
    "\n",
    "    # üîπ Get Top Matching Questions\n",
    "    top_indices = np.argsort(final_scores)[-top_k:][::-1]\n",
    "\n",
    "    # üîπ Retrieve Best Matching Answer\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        matched_question = df.iloc[idx][\"Question\"]\n",
    "        matched_answer = df.iloc[idx][\"Clean_Answer\"]\n",
    "        score = final_scores[idx]\n",
    "        results.append((matched_question, matched_answer, score))\n",
    "\n",
    "    return results\n",
    "\n",
    "# ‚úÖ Step 8: Test the Answer Retrieval\n",
    "input_question = \"What are the symptoms of diabetes?\"\n",
    "retrieved_answers = retrieve_best_answer(input_question, top_k=1)\n",
    "\n",
    "# ‚úÖ Step 9: Display Retrieved Answer\n",
    "print(\"\\nüîç **Input Question:**\", input_question)\n",
    "print(\"\\nüéØ **Best Matched Answer:**\")\n",
    "for idx, (matched_question, answer, score) in enumerate(retrieved_answers, start=1):\n",
    "    print(f\"{idx}. Matched Question: {matched_question} (Score: {score:.4f})\")\n",
    "    print(f\"   ‚úÖ Answer: {answer}\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/charupatelbaghi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/charupatelbaghi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/charupatelbaghi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Available Columns: Index(['Question', 'Clean_Answer'], dtype='object')\n",
      "\n",
      "üì¢ Extracted Questions Sample:\n",
      "0    What is (are) Polycystic ovary syndrome ? (Als...\n",
      "1    What causes Polycystic ovary syndrome ? (Also ...\n",
      "2                        What causes Noonan syndrome ?\n",
      "3      What are the complications of Noonan syndrome ?\n",
      "4                     How to prevent Noonan syndrome ?\n",
      "5    What are the symptoms of Neurofibromatosis-Noo...\n",
      "6    Is Noonan syndrome inherited ? (Also called: M...\n",
      "7    What are the treatments for Noonan syndrome ? ...\n",
      "8    How many people are affected by polycystic kid...\n",
      "9    What are the treatments for polycystic kidney ...\n",
      "Name: Question, dtype: object\n",
      "\n",
      "üìä Question Embeddings Shape: torch.Size([1805, 384])\n",
      "\n",
      "üîç **Input Question:** What are the symptoms of diabetes?\n",
      "\n",
      "üéØ **Best Matched Answer:**\n",
      "1. Matched Question: What is (are) Diabetes ? (Score: 0.6757)\n",
      "   ‚úÖ Answer: URL: http://nihseniorhealth.gov/diabetes/toc.html\n",
      "Answer: Heart disease and stroke are the leading causes of death for people with diabetes. Controlling the ABCs of diabetes -- your blood glucose, your blood pressure, and your cholesterol, as well as stopping smoking -- can help prevent these and other complications from diabetes. -  A is for the A1C test  -  B is for Blood pressure  -  C is for Cholesterol. A is for the A1C test B is for Blood pressure C is for Cholesterol. - The A1C test (A-one-C) shows you what your blood glucose has been over the last three months. Your health care provider does this test to see what your blood glucose level is most of the time. This test should be done at least twice a year for all people with diabetes and for some people more often as needed. For many people with diabetes, an A1C test result of under 7 percent usually means that their diabetes treatment is working well and their blood glucose is under control.  The A1C test (A-one-C) shows you what your blood glucose has been over the last three months. Your health care provider does this test to see what your blood glucose level is most of the time. This test should be done at least twice a year for all people with diabetes and for some people more often as needed. For many people with diabetes, an A1C test result of under 7 percent usually means that their diabetes treatment is working well and their blood glucose is under control. -  B is for Blood pressure. The goal for most people is 140/90 but may be different for you. High blood pressure makes your heart work too hard. It can cause heart attack, stroke, and kidney disease. Your blood pressure should be checked at every doctor visit. Talk with your health care provider about your blood pressure goal.  B is for Blood pressure. The goal for most people is 140/90 but may be different for you. High blood pressure makes your heart work too hard. It can cause heart attack, stroke, and kidney disease. Your blood pressure should be checked at every doctor visit. Talk with your health care provider about your blood pressure goal. - C is for Cholesterol (ko-LES-ter-ol). The LDL goal for most people is less than 100. Low density lipoprotein, or LDL-cholesterol, is the bad cholesterol that builds up in your blood vessels. It causes the vessels to narrow and harden, which can lead to a heart attack. Your doctor should check your LDL at least once a year. Talk with your health care provider about your cholesterol goal.  C is for Cholesterol (ko-LES-ter-ol). The LDL goal for most people is less than 100. Low density lipoprotein, or LDL-cholesterol, is the bad cholesterol that builds up in your blood vessels. It causes the vessels to narrow and harden, which can lead to a heart attack. Your doctor should check your LDL at least once a year. Talk with your health care provider about your cholesterol goal. Ask your health care team - what your A1C, blood pressure, and cholesterol numbers are.  - what your ABCs should be.  - what you can do to reach your target.  what your A1C, blood pressure, and cholesterol numbers are. what your ABCs should be. what you can do to reach your target.) \n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T10:23:03.492081Z",
     "start_time": "2025-04-12T10:22:35.256733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This piece of CODE gives us three most relevant  matched questions and answers from the data set .\n",
    "# I haven't made translations into this for now!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# ‚úÖ Load & Process Dataset\n",
    "file_path = \"Extracted_Medical_Q_A.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ‚úÖ Check necessary columns\n",
    "if \"Question\" not in df.columns or \"Clean_Answer\" not in df.columns:\n",
    "    raise KeyError(\"Missing 'Question' or 'Clean_Answer' column in dataset.\")\n",
    "\n",
    "# ‚úÖ Remove Duplicates & NaNs\n",
    "df = df.dropna(subset=[\"Question\", \"Clean_Answer\"]).drop_duplicates(subset=[\"Question\"]).reset_index(drop=True)\n",
    "\n",
    "# ‚úÖ Load Pretrained BERT Model\n",
    "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ‚úÖ Compute Sentence Embeddings\n",
    "question_embeddings = bert_model.encode(df[\"Question\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "# ‚úÖ Check if embeddings exist\n",
    "if question_embeddings.shape[0] == 0:\n",
    "    raise ValueError(\"No question embeddings found. Check dataset processing!\")\n",
    "\n",
    "# ‚úÖ Preprocessing Functions\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def truncate_answer(answer, max_sentences=3):\n",
    "    import re\n",
    "    sentences = re.split(r'(?<=[.!?]) +', answer.strip())\n",
    "    return ' '.join(sentences[:max_sentences])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    processed_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return \" \".join(processed_tokens)\n",
    "\n",
    "# ‚úÖ Train TF-IDF Model\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"Question\"].apply(preprocess_text))\n",
    "\n",
    "# ‚úÖ Hybrid Retrieval\n",
    "def retrieve_best_answer(input_question, top_k=3, match_threshold=0.90):\n",
    "    processed_input = preprocess_text(input_question)\n",
    "    input_vector = vectorizer.transform([processed_input])\n",
    "    tfidf_scores = np.dot(input_vector, tfidf_matrix.T).toarray().flatten()\n",
    "    input_embedding = bert_model.encode([input_question], convert_to_tensor=True).view(1, -1)\n",
    "    bert_scores = util.pytorch_cos_sim(input_embedding, question_embeddings)[0].cpu().numpy()\n",
    "    final_scores = (tfidf_scores * 0.4) + (bert_scores * 0.6)\n",
    "    top_indices = np.argsort(final_scores)[-top_k:][::-1]\n",
    "\n",
    "    best_idx = top_indices[0]\n",
    "    best_score = final_scores[best_idx]\n",
    "    matched_question = df.iloc[best_idx][\"Question\"]\n",
    "    matched_answer = df.iloc[best_idx][\"Clean_Answer\"]\n",
    "\n",
    "    if matched_question.strip().lower() == input_question.strip().lower() or best_score >= match_threshold:\n",
    "        return [(matched_question, truncate_answer(matched_answer), best_score)]\n",
    "\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        matched_q = df.iloc[idx][\"Question\"]\n",
    "        matched_a = df.iloc[idx][\"Clean_Answer\"]\n",
    "        score = final_scores[idx]\n",
    "        results.append((matched_q, truncate_answer(matched_a), score))\n",
    "\n",
    "    return results\n",
    "\n",
    "# ‚úÖ Example Run (Only Output Relevant Answers)\n",
    "# ‚úÖ Example Run (Take Input from User)\n",
    "while True:\n",
    "    input_question = input(\"‚ùì Enter your medical question (or type 'exit' to quit): \")\n",
    "\n",
    "    if input_question.strip().lower() == \"exit\":\n",
    "        print(\"üëã Exiting. Stay healthy!\")\n",
    "        break\n",
    "\n",
    "    retrieved_answers = retrieve_best_answer(input_question, top_k=3)\n",
    "\n",
    "    print(\"\\nüîç Top Matching Results:\\n\")\n",
    "    for idx, (matched_question, answer, score) in enumerate(retrieved_answers, start=1):\n",
    "        print(f\"{idx}. Matched Question: {matched_question} (Score: {score:.4f})\")\n",
    "        print(f\"   ‚úÖ Answer: {answer}\\n\")\n",
    "\n"
   ],
   "id": "38bcdb019416a47a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/charupatelbaghi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/charupatelbaghi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/charupatelbaghi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Top Matching Results:\n",
      "\n",
      "1. Matched Question: Do you have information about Glucose urine test (Also called: Urine sugar test; Urine glucose test; Glucosuria test; Glycosuria test) (Score: 0.8511)\n",
      "   ‚úÖ Answer: URL: https://www.nlm.nih.gov/medlineplus/ency/article/003581.htm\n",
      "Answer: Summary : The glucose urine test measures the amount of sugar (glucose) in a urine sample. The presence of glucose in the urine is called glycosuria or glucosuria.  Glucose level can also be measured using a blood test or a cerebrospinal fluid test.\n",
      "\n",
      "How the Test is Performed : After you provide a urine sample, it is tested right away. The health care provider uses a dipstick made with a color-sensitive pad. The color the dipstick changes to tells the provider the level of glucose in your urine.   If needed,your provider may ask you to collect your urine at home over 24 hours. Your provider will tell you how to do this. Follow instructions exactly so that the results are accurate.\n",
      "\n",
      "How to Prepare for the Test : Certain medicinescan change the result of this test. Before the test, tell your provider which medicines you are taking. Do not stop taking any medicine before talking to your provider.\n",
      "\n",
      "How the Test will Feel : The test involves only normal urination. There is no discomfort.\n",
      "\n",
      "Why the Test is Performed : This test was commonly used to test for and monitor diabetes in the past. Now, blood tests to measure glucose level in the blood are easy to do and are used instead of the glucose urine test.  The glucose urine test may be ordered when the doctor suspects renal glycosuria. This is a rare condition in which glucose is released from the kidneys into the urine, even when the blood glucose level is normal.\n",
      "\n",
      "Normal Results : Glucose is not usually found in urine. If it is, further testing is needed.  Normal glucose range in urine: 0to 0.8 mmol/l (0to 15 mg/dL)  The examples above are common measurements for results of these tests. Normal value ranges may vary slightly among different laboratories. Some labs use different measurements or test different samples. Talk to yourhealth care providerabout the meaning of your specific test results.\n",
      "\n",
      "What Abnormal Results Mean : Higher than normal levels of glucose may occur with:  - Diabetes: Small increases in urine glucose levels after a large meal are not always a cause for concern.    - Pregnancy: Up to half of women have glucose in their urine at sometime during pregnancy. Glucose in the urine may mean that a woman has gestational diabetes.  - Renal glycosuria: A rare condition in which glucose is released from the kidneys into the urine, even when blood glucose levelsare normal.\n",
      "\n",
      "Risks : There are no risks with this test.) \n",
      "\n",
      "\n",
      "2. Matched Question: Do you have information about CSF glucose test (Also called: Glucose test - CSF; Cerebrospinal fluid glucose test) (Score: 0.6575)\n",
      "   ‚úÖ Answer: URL: https://www.nlm.nih.gov/medlineplus/ency/article/003633.htm\n",
      "Answer: Summary : A CSF glucose test measures the amount of sugar (glucose) in the cerebrospinal fluid (CSF). CSF is a clear fluid that flows in the space surrounding the spinal cord and brain.\n",
      "\n",
      "How the Test is Performed : A sample of CSF is needed. A lumbar puncture, also called a spinal tap, is the most common way to collect this sample. For information on this procedure, see the article on lumbar puncture.  Other methods for collecting CSF are rarely used, but may be recommended in some cases. They include:  - Cisternal puncture  - Ventricular puncture  - Removal of CSF from a tube that is already in the CSF, such as a shunt or ventricular drain    The sample is sent to a laboratory for testing.\n",
      "\n",
      "Why the Test is Performed : This test may be done to diagnose:  - Tumors  - Infections  - Inflammation of the central nervous system  - Delirium  - Other neurological and medical conditions\n",
      "\n",
      "Normal Results : The glucose level in the CSF should be 50 to 80 mg/100 mL (or greater than 2/3 of the blood sugar level).  Note: Normal value ranges may vary slightly among different laboratories. Talk to your health care provider about the meaning of your specific test results.  The examples above show the common measurements for results for these tests. Some laboratories use different measurements or may test different specimens.\n",
      "\n",
      "What Abnormal Results Mean : Abnormal results include higher and lower glucose levels. Abnormal results may be due to:  - Infection (bacterial or fungus)  - Inflammation of the central nervous system  - Tumor) \n",
      "\n",
      "\n",
      "3. Matched Question: Do you have information about Urine and Urination (Score: 0.6026)\n",
      "   ‚úÖ Answer: URL: https://www.nlm.nih.gov/medlineplus/urineandurination.html\n",
      "Answer: Summary : Your kidneys make urine by filtering wastes and extra water from your blood. The waste is called urea. Your blood carries it to the kidneys. From the kidneys, urine travels down two thin tubes called ureters to the bladder. The bladder stores urine until you are ready to urinate. It swells into a round shape when it is full and gets smaller when empty. If your urinary system is healthy, your bladder can hold up to 16 ounces (2 cups) of urine comfortably for 2 to 5 hours.    You may have problems with urination if you have       - Kidney failure    - Urinary tract infections     - An enlarged prostate    - Bladder control problems like incontinence, overactive bladder, or interstitial cystitis    - A blockage that prevents you from emptying your bladder        Some conditions may also cause you to have blood or protein in your urine. If you have a urinary problem, see your healthcare provider. Urinalysis and other urine tests can help to diagnose the problem. Treatment depends on the cause.    NIH: National Institute of Diabetes and Digestive and Kidney Diseases) \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 87\u001B[39m\n\u001B[32m     84\u001B[39m \u001B[38;5;66;03m# ‚úÖ Example Run (Only Output Relevant Answers)\u001B[39;00m\n\u001B[32m     85\u001B[39m \u001B[38;5;66;03m# ‚úÖ Example Run (Take Input from User)\u001B[39;00m\n\u001B[32m     86\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m87\u001B[39m     input_question = \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m‚ùì Enter your medical question (or type \u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mexit\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m to quit): \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     89\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m input_question.strip().lower() == \u001B[33m\"\u001B[39m\u001B[33mexit\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m     90\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33müëã Exiting. Stay healthy!\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/PythonProject/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001B[39m, in \u001B[36mKernel.raw_input\u001B[39m\u001B[34m(self, prompt)\u001B[39m\n\u001B[32m   1280\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1281\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[32m-> \u001B[39m\u001B[32m1282\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1283\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1284\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1285\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1286\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1287\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/PythonProject/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001B[39m, in \u001B[36mKernel._input_request\u001B[39m\u001B[34m(self, prompt, ident, parent, password)\u001B[39m\n\u001B[32m   1322\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[32m   1323\u001B[39m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[32m   1324\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mInterrupted by user\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1325\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1326\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1327\u001B[39m     \u001B[38;5;28mself\u001B[39m.log.warning(\u001B[33m\"\u001B[39m\u001B[33mInvalid Message:\u001B[39m\u001B[33m\"\u001B[39m, exc_info=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T10:34:09.460132Z",
     "start_time": "2025-04-12T10:34:09.092946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from IndicTransToolkit.IndicTransToolkit import IndicProcessor\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def initialize_model_and_tokenizer(ckpt_dir, quantization):\n",
    "    if quantization == \"4-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    elif quantization == \"8-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            bnb_8bit_use_double_quant=True,\n",
    "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    else:\n",
    "        qconfig = None\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ckpt_dir, trust_remote_code=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        quantization_config=qconfig,\n",
    "    )\n",
    "\n",
    "    if qconfig == None:\n",
    "        model = model.to(DEVICE)\n",
    "        if DEVICE == \"cuda\":\n",
    "            model.half()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip):\n",
    "    translations = []\n",
    "    for i in range(0, len(input_sentences), BATCH_SIZE):\n",
    "        batch = input_sentences[i : i + BATCH_SIZE]\n",
    "\n",
    "        # Preprocess the batch and extract entity mappings\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "        # Tokenize the batch and generate input encodings\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # Generate translations using the model\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=0,\n",
    "                max_length=256,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1,\n",
    "            )\n",
    "\n",
    "        # Decode the generated tokens into text\n",
    "\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            generated_tokens = tokenizer.batch_decode(\n",
    "                generated_tokens.detach().cpu().tolist(),\n",
    "                skip_special_tokens=True,\n",
    "                clean_up_tokenization_spaces=True,\n",
    "            )\n",
    "\n",
    "        # Postprocess the translations, including entity replacement\n",
    "        translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return translations"
   ],
   "id": "dc82e640cbdba658",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Maincode + translation logic -final",
   "id": "3048d0935808fc5"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-12T11:09:01.837976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === IMPORTS ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "import scispacy\n",
    "import spacy\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# === DOWNLOAD NLTK STUFF ===\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# === LOAD NLP & MODELS ===\n",
    "nlp = spacy.load(\"en_core_sci_sm\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# === LOAD DATASET ===\n",
    "file_path = \"Extracted_Medical_Q_A.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "if \"Question\" not in df.columns or \"Clean_Answer\" not in df.columns:\n",
    "    raise KeyError(\"Missing 'Question' or 'Clean_Answer' column in dataset.\")\n",
    "\n",
    "df = df.dropna(subset=[\"Question\", \"Clean_Answer\"]).drop_duplicates(subset=[\"Question\"]).reset_index(drop=True)\n",
    "\n",
    "# === LOAD EMBEDDINGS ===\n",
    "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "question_embeddings = bert_model.encode(df[\"Question\"].tolist(), convert_to_tensor=True)\n",
    "\n",
    "# === TF-IDF ===\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    processed_tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return \" \".join(processed_tokens)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"Question\"].apply(preprocess_text))\n",
    "\n",
    "# === TRANSLATION MODEL LOADING ===\n",
    "def load_translation_models():\n",
    "    en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"\n",
    "    indic_en_ckpt_dir = \"ai4bharat/indictrans2-indic-en-dist-200M\"\n",
    "\n",
    "    en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, None)\n",
    "    indic_en_tokenizer, indic_en_model = initialize_model_and_tokenizer(indic_en_ckpt_dir, None)\n",
    "\n",
    "    ip = IndicProcessor(inference=True)\n",
    "    return (en_indic_tokenizer, en_indic_model), (indic_en_tokenizer, indic_en_model), ip\n",
    "\n",
    "# === TRANSLATION WRAPPER ===\n",
    "def translate_text(text, src_lang, tgt_lang, model, tokenizer, ip):\n",
    "    try:\n",
    "        translations = batch_translate([text], src_lang, tgt_lang, model, tokenizer, ip)\n",
    "        return translations[0] if translations else None\n",
    "    except Exception as e:\n",
    "        print(f\"Translation Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# === TRUNCATE LONG ANSWERS ===\n",
    "def truncate_answer(answer, max_sentences=3):\n",
    "    import re\n",
    "    sentences = re.split(r'(?<=[.!?]) +', answer.strip())\n",
    "    return ' '.join(sentences[:max_sentences])\n",
    "\n",
    "# === MAIN RETRIEVAL LOGIC ===\n",
    "def retrieve_best_answer(input_question_en, top_k=3, match_threshold=0.90):\n",
    "    processed_input = preprocess_text(input_question_en)\n",
    "    input_vector = vectorizer.transform([processed_input])\n",
    "    tfidf_scores = np.dot(input_vector, tfidf_matrix.T).toarray().flatten()\n",
    "    input_embedding = bert_model.encode([input_question_en], convert_to_tensor=True).view(1, -1)\n",
    "    bert_scores = util.pytorch_cos_sim(input_embedding, question_embeddings)[0].cpu().numpy()\n",
    "    final_scores = (tfidf_scores * 0.4) + (bert_scores * 0.6)\n",
    "    top_indices = np.argsort(final_scores)[-top_k:][::-1]\n",
    "\n",
    "    best_idx = top_indices[0]\n",
    "    best_score = final_scores[best_idx]\n",
    "    matched_question = df.iloc[best_idx][\"Question\"]\n",
    "    matched_answer = df.iloc[best_idx][\"Clean_Answer\"]\n",
    "\n",
    "    if matched_question.strip().lower() == input_question_en.strip().lower() or best_score >= match_threshold:\n",
    "        return [(matched_question, truncate_answer(matched_answer), best_score)]\n",
    "\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        matched_q = df.iloc[idx][\"Question\"]\n",
    "        matched_a = df.iloc[idx][\"Clean_Answer\"]\n",
    "        score = final_scores[idx]\n",
    "        results.append((matched_q, truncate_answer(matched_a), score))\n",
    "\n",
    "    return results\n",
    "\n",
    "# === COMBINED RETRIEVAL SYSTEM: PUNJABI ENGLISH PUNJABI ===\n",
    "def punjabi_medical_qa_clir(punjabi_query, top_k=3):\n",
    "    (en_indic_tokenizer, en_indic_model), (indic_en_tokenizer, indic_en_model), ip = load_translation_models()\n",
    "\n",
    "    # Step 1: Translate Punjabi to English\n",
    "    print(\"\\nüîÑ Translating Punjabi query to English...\")\n",
    "    english_query = translate_text(punjabi_query, \"pan_Guru\", \"eng_Latn\", indic_en_model, indic_en_tokenizer, ip)\n",
    "    if not english_query:\n",
    "        return [\"‚ùå Translation to English failed. Please try again.\"]\n",
    "\n",
    "    print(f\"\\nüîé Translated Query (EN): {english_query}\")\n",
    "\n",
    "    # Step 2: Retrieve top answers in English\n",
    "    print(\"\\nüì° Retrieving top answers in English...\")\n",
    "    results = retrieve_best_answer(english_query, top_k=top_k)\n",
    "\n",
    "    print(\"\\nüéØ Retrieved answers in English:\")\n",
    "    for idx, (matched_question, answer, score) in enumerate(results, 1):\n",
    "        print(f\"{idx}. {matched_question} \\nAnswer: {answer} (Score: {score:.4f})\")\n",
    "\n",
    "    # Step 3: Translate results back to Punjabi\n",
    "    print(\"\\nüîÑ Translating results back to Punjabi...\")\n",
    "    punjabi_outputs = []\n",
    "    for idx, (matched_question, answer, score) in enumerate(results, 1):\n",
    "        translated_answer = translate_text(answer, \"eng_Latn\", \"pan_Guru\", en_indic_model, en_indic_tokenizer, ip)\n",
    "        if not translated_answer:\n",
    "            translated_answer = \"‚ùå Translation error while returning result.\"\n",
    "\n",
    "        punjabi_outputs.append(f\"{idx}. {translated_answer} (Score: {score:.4f})\")\n",
    "\n",
    "    return punjabi_outputs\n",
    "\n",
    "# === INTERACTIVE MODE ===\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        query = input(\"\\nü§ñ ‡®§‡©Å‡®π‡®æ‡®°‡®æ ‡®Æ‡©à‡®°‡©Ä‡®ï‡®≤ ‡®∏‡®µ‡®æ‡®≤ ‡®¶‡®∞‡®ú ‡®ï‡®∞‡©ã (Punjabi) (or type 'exit'): \").strip()\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"üëã Exiting. Stay healthy!\")\n",
    "            break\n",
    "\n",
    "        answers = punjabi_medical_qa_clir(query, top_k=3)\n",
    "        print(\"\\nüìã ‡®â‡®ö‡®ø‡®§ ‡®ú‡®µ‡®æ‡®¨ (Punjabi Summaries):\\n\")\n",
    "        for line in answers:\n",
    "            print(line)\n",
    "\n"
   ],
   "id": "6978b33d3ce66d22",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/charupatelbaghi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/charupatelbaghi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/charupatelbaghi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7e35226a900e4ed3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
